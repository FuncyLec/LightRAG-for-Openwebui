# LightRAG-for-Openwebui

è¿™æ˜¯ä¸€ä¸ªLightRAGçš„APIæ¨¡æ‹Ÿå™¨ï¼Œç”¨äºåœ¨Openwebuiä¸­é€šè¿‡è‡ªå¸¦çš„Ollamaæ¥å£ä½¿ç”¨LightRAGï¼›é€šè¿‡å¯¹è¯æ—¶ä½¿ç”¨å‰ç¼€ï¼Œè¿˜å¯ä»¥å®ç°lightragçš„æ¨¡å¼åˆ‡æ¢ã€‚  
<small style="color:gray;">This is an API simulator for LightRAG, used to utilize LightRAG in Openwebui through the built-in Ollama interface; mode switching of LightRAG can also be achieved by using prefixes during conversations.</small>

## ğŸ‰ğŸ‰ğŸ‰ å£°æ˜ ğŸ‰ğŸ‰ğŸ‰  
<small style="color:gray;">## ğŸ‰ğŸ‰ğŸ‰ Disclaimer ğŸ‰ğŸ‰ğŸ‰</small>

ç”±äºæœ¬äººæ²¡æœ‰æ¥è§¦è¿‡pythonå’Œapiçš„å„ç§çŸ¥è¯†ï¼Œæ›´ä¸ä¼šäºŒæ¬¡å¼€å‘openwebuiï¼Œä»£ç æ˜¯ç½‘ä¸Šå­¦ä¹ è¿‡ç¨‹ä¸­ä½¿ç”¨AIå·¥å…·ç¼–å†™ï¼ˆåŒ…æ‹¬è¿™ä¸ªREADME.mdï¼‰ï¼Œæ„Ÿè°¢äº’è”ç½‘ä¸Šå¤§å®¶çš„å¼€æºå†…å®¹å’Œå…è´¹æä¾›çš„å„ç§aiå·¥å…·ï¼Œä½¿å¾—æˆ‘å¯ä»¥ä¸Šä¼ æˆ‘çš„ç¬¬ä¸€ä¸ªgithubå°é¡¹ç›®ã€‚å°½ç®¡ä»£ç å®ç°è¿‡ç¨‹å¹¶ä¸ä¼˜ç¾ï¼Œä½†èƒœåœ¨ç®€å•æ˜“ç”¨ã€‚å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»æˆ‘åˆ é™¤ã€‚  
<small style="color:gray;">Since I have no prior knowledge of Python and APIs, nor the ability to redevelop Openwebui, the code was written using AI tools during online learning (including this README.md). Thanks to everyone's open-source content and various free AI tools available on the internet, I was able to upload my first GitHub project. Although the code implementation is not elegant, it is simple and easy to use. If you have any questions or suggestions, please contact me for removal.</small>

## ğŸš€ å¿«é€Ÿå¼€å§‹  
<small style="color:gray;">## ğŸš€ Quick Start</small>

1. é¦–å…ˆä½ éœ€è¦æ­£ç¡®é…ç½®Lightragçš„apiæœåŠ¡å™¨ï¼ˆ[API Server Implementation](https://github.com/HKUDS/LightRAG/blob/main/README.md#api-server-implementation)ï¼‰ï¼Œå¹¶ç¡®ä¿å¯ä»¥æ­£å¸¸è®¿é—®ã€‚  
   <small style="color:gray;">First, you need to properly configure the Lightrag API server ([API Server Implementation](https://github.com/HKUDS/LightRAG/blob/main/README.md#api-server-implementation)) and ensure it is accessible.</small>

2. ç„¶åä½ éœ€è¦æ­£ç¡®å®‰è£…Openwebuiï¼ˆ[How to Install](https://github.com/open-webui/open-webui?tab=readme-ov-file#how-to-install-)ï¼‰ã€‚  
   <small style="color:gray;">Then, you need to properly install Openwebui ([How to Install](https://github.com/open-webui/open-webui?tab=readme-ov-file#how-to-install-)).</small>

3. å¯åŠ¨`ApiSimulator.py`ï¼ˆä»£ç å—ï¼š`python ApiSimulator.py`ï¼‰ï¼Œè½¬å‘æœåŠ¡ä¼šå¯åŠ¨åœ¨`localhost:3030`ã€‚  
   <small style="color:gray;">Start `ApiSimulator.py` (command: `python ApiSimulator.py`), the forwarding service will start on `localhost:3030`.</small>

4. æ‰“å¼€openwebuiï¼Œåœ¨è®¾ç½®ä¸­æ·»åŠ ä¸€ä¸ªOllamaèŠ‚ç‚¹ï¼Œåœ°å€è®¾ç½®ä¸º`localhost:11434`ï¼Œç„¶åç‚¹å‡»`Verify connection`ï¼Œæ­¤æ—¶Openwebuiä¼šæç¤ºéªŒè¯æˆåŠŸï¼Œ`ApiSimulator.py`çš„è¿è¡Œç»ˆç«¯ä¼šæç¤º`GET /api/version`å’Œ`GET /api/tags`æˆåŠŸã€‚  
   <small style="color:gray;">Open Openwebui, add an Ollama node in the settings, set the address to `localhost:11434`, then click `Verify connection`. Openwebui will indicate a successful verification, and the terminal running `ApiSimulator.py` will show `GET /api/version` and `GET /api/tags` success.</small>

5. åœ¨Openwebuiåˆ›å»ºæ–°å¯¹è¯ï¼Œæ­¤æ—¶ä¼šæ˜¾ç¤º`LightragModel:latest`ï¼Œé€‰æ‹©è¯¥æ¨¡å‹ï¼Œå³å¯ä½¿ç”¨LightRAGã€‚  
   <small style="color:gray;">Create a new conversation in Openwebui, `LightragModel:latest` will be displayed, select this model to use LightRAG.</small>

## âš™ï¸ é…ç½®é€‰é¡¹  
<small style="color:gray;">## âš™ï¸ Configuration Options</small>

åœ¨ `ApiSimulator.py` æ–‡ä»¶ä¸­æä¾›äº†ä»¥ä¸‹é…ç½®é€‰é¡¹ï¼š  
<small style="color:gray;">The following configuration options are provided in the `ApiSimulator.py` file:</small>

- `OLLAMA_API_URL = "http://localhost:11434"`  Ollama çš„ API åœ°å€ï¼Œå¦‚æœä½ ä½¿ç”¨äº† Ollama çš„æœåŠ¡ï¼Œè¿™ä¸ªåœ°å€å¯ä»¥å‚è€ƒä½ çš„ Ollama æœåŠ¡æä¾›çš„ API ä¿¡æ¯æ¥è¿”å›ç‰ˆæœ¬è¯·æ±‚ç­‰ã€‚  
  <small style="color:gray;">Ollama's API address. If you are using Ollama's service, this address can refer to the API information provided by your Ollama service to return version requests, etc.</small>

- `SERVER_PORT = 3030`  è½¬å‘æœåŠ¡çš„ç«¯å£ã€‚  
  <small style="color:gray;">The port for the forwarding service.</small>

- `LIGHTRAG_API_URL = "http://localhost:8020"`  LightRAG API åœ°å€ã€‚  
  <small style="color:gray;">LightRAG API address.</small>

- `FAKE_MODEL_NAME = "LightragModel:latest"`  æ¨¡å‹åç§°ï¼Œå¯ä»¥éšæ„å†™ã€‚  
  <small style="color:gray;">Model name, can be written arbitrarily.</small>

- `FORWARD_MODE = False`  API è¯·æ±‚è½¬å‘å¼€å…³ï¼Œæ‰“å¼€ä¹‹åä¼šç›´æ¥è½¬å‘æ‰€æœ‰è¯·æ±‚åˆ° Ollamaï¼Œç”¨äºæµ‹è¯•ã€‚  
  <small style="color:gray;">API request forwarding switch. When turned on, all requests will be directly forwarded to Ollama for testing.</small>

- `PREFIX_MODE_SWITCH = True`  å‰ç¼€è§¦å‘è¯åŠŸèƒ½å¼€å…³ï¼Œæ‰“å¼€ä¹‹åï¼Œå¯¹è¯æ—¶è¾“å…¥çš„å†…å®¹ä¼šæ ¹æ®å‰ç¼€æ¥åˆ¤æ–­è°ƒç”¨æ¨¡å¼ï¼Œé»˜è®¤ä¸º hybridã€‚  
  <small style="color:gray;">Prefix trigger word function switch. When turned on, the input content during conversation will determine the call mode based on the prefix, default is hybrid.</small>

- `LOCAL_PREFIX = "_å…·ä½“åœ°ï¼š"`  è§¦å‘ local æ¨¡å¼çš„å‰ç¼€ã€‚  
  <small style="color:gray;">Prefix to trigger local mode.</small>

- `GLOBAL_PREFIX = "_æ¦‚æ‹¬åœ°ï¼š"`  è§¦å‘ global æ¨¡å¼çš„å‰ç¼€ã€‚  
  <small style="color:gray;">Prefix to trigger global mode.</small>

- `NAIVE_PREFIX = "_ç®€å•åœ°ï¼š"`  è§¦å‘ naive æ¨¡å¼çš„å‰ç¼€ã€‚  
  <small style="color:gray;">Prefix to trigger naive mode.</small>
